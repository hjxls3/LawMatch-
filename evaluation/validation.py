import os
import json
import re
from tqdm import tqdm

# è·¯å¾„é…ç½®
base_dir = os.path.dirname(__file__)
test_path = os.path.join(base_dir, "..", "data", "test2.0.jsonl")
result_path = os.path.join(base_dir, "..", "outputs", "test_results3.0_base.jsonl")
output_path = os.path.join(base_dir, "..", "outputs", "test_results3.0_base_valid.jsonl")
accu_path = os.path.join(base_dir, "..", "meta", "accu.txt")
law_path = os.path.join(base_dir, "..", "meta", "law.txt")

def load_txt(file_path):
    """ åŠ è½½ txt æ–‡ä»¶ï¼Œè¿”å›é›†åˆ """
    with open(file_path, "r", encoding="utf-8") as file:
        return set(line.strip() for line in file if line.strip())

def load_jsonl(file_path):
    """ åŠ è½½ jsonl æ–‡ä»¶ï¼Œè¿”å›åˆ—è¡¨ """
    data = []
    with open(file_path, "r", encoding="utf-8") as file:
        for line in file:
            try:
                data.append(json.loads(line.strip()))
            except json.JSONDecodeError:
                print(f"âš ï¸ JSON è§£æå¤±è´¥ï¼š{line.strip()}")
    return data

def normalize_accusation(accusation):
    """
    æ ‡å‡†åŒ–ç½ªåï¼š
    - åˆ é™¤ä¸­æ‹¬å·ï¼Œä»…ä¿ç•™å†…å®¹ï¼›
    - å»é™¤ "ç½ª" å­—åç¼€ã€‚
    """
    # åˆ é™¤ä¸­æ‹¬å·æœ¬èº«ï¼Œä»…ä¿ç•™å…¶ä¸­å†…å®¹
    accusation = re.sub(r"[\[\]]", "", accusation).strip()

    # å»é™¤ "ç½ª" å­—åç¼€
    if accusation.endswith("ç½ª"):
        accusation = accusation[:-1]

    return accusation



def validate_and_save(test_data, result_data, valid_accusations, valid_articles, output_path):
    """
    éå†ç”Ÿæˆç»“æœï¼Œå°†éæ³•æ ·æœ¬ç½®ç©ºï¼Œå¹¶å°†åˆæ³•æ ·æœ¬ä¸­çš„â€œç½ªâ€å­—å»é™¤åä¿å­˜ã€‚
    """
    total_samples = len(test_data)
    structured_samples = 0
    valid_samples = 0

    with open(output_path, "w", encoding="utf-8") as outfile:
        for true_item, pred_item in zip(test_data, result_data):
            pred_meta = pred_item.get("meta", {})
            accusations = pred_meta.get("accusation", [])
            articles = pred_meta.get("relevant_articles", [])

            # åˆ¤æ–­æ˜¯å¦ç»“æ„åŒ–è¾“å‡º
            is_structured = bool(accusations) and bool(articles)

            if is_structured:
                structured_samples += 1

                # æ ‡å‡†åŒ–ç½ªåï¼šå»é™¤â€œç½ªâ€å­—åç¼€
                normalized_accusations = [normalize_accusation(acc) for acc in accusations]

                # æ£€æŸ¥åˆæ³•æ€§
                invalid_accusations = [acc for acc in normalized_accusations if acc not in valid_accusations]
                invalid_articles = [art for art in articles if art not in valid_articles]

                # åˆæ³•æ ·æœ¬ï¼Œä¿å­˜æ ‡å‡†åŒ–åçš„æ•°æ®
                if not invalid_accusations and not invalid_articles:
                    valid_samples += 1
                    cleaned_data = {
                        "meta": {
                            "accusation": normalized_accusations,
                            "relevant_articles": articles
                        }
                    }
                    outfile.write(json.dumps(cleaned_data, ensure_ascii=False) + "\n")
                else:
                    # ç½®ç©º
                    empty_data = {"meta": {"accusation": [], "relevant_articles": []}}
                    outfile.write(json.dumps(empty_data, ensure_ascii=False) + "\n")

            else:
                # ç½®ç©º
                empty_data = {"meta": {"accusation": [], "relevant_articles": []}}
                outfile.write(json.dumps(empty_data, ensure_ascii=False) + "\n")

    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    structured_rate = structured_samples / total_samples if total_samples > 0 else 0
    valid_rate = valid_samples / structured_samples if structured_samples > 0 else 0

    print("\nğŸ“Š è¯„ä¼°ç»“æœï¼š")
    print(f"ç»“æ„åŒ–ç‡ï¼š{structured_rate:.4f}")
    print(f"åˆæ³•ç‡ï¼ˆåˆæ³•æ ·æœ¬ç‡ï¼ŒåŸºäºç»“æ„åŒ–æ ·æœ¬ï¼‰ï¼š{valid_rate:.4f}")
    print(f"âœ… åˆæ³•æ ·æœ¬å·²ä¿å­˜è‡³ {output_path}")

def main():
    # åŠ è½½æ•°æ®
    print("ğŸ”„ æ­£åœ¨åŠ è½½æ•°æ®...")
    test_data = load_jsonl(test_path)
    result_data = load_jsonl(result_path)
    valid_accusations = load_txt(accu_path)
    valid_articles = set(map(int, load_txt(law_path)))  # è½¬ä¸ºæ•´æ•°

    # æ‰§è¡Œæ¸…ç†å¹¶ä¿å­˜
    validate_and_save(test_data, result_data, valid_accusations, valid_articles, output_path)

if __name__ == "__main__":
    main()
