import os
import json
import re
from collections import defaultdict
from tqdm import tqdm

# è·¯å¾„é…ç½®
base_dir = os.path.dirname(__file__)
test_path = os.path.join(base_dir, "..", "data", "test2.0.jsonl")
result_path = os.path.join(base_dir, "..", "outputs", "test_results3.0_base_valid.jsonl")


def normalize_accusation(acc):
    """ å»æ‰ä¸­æ‹¬å·å’Œâ€˜ç½ªâ€™å­— """
    acc = re.sub(r"[\[\]]", "", acc).strip()
    return acc[:-1] if acc.endswith("ç½ª") else acc

def load_jsonl(file_path):
    """ åŠ è½½ jsonl æ–‡ä»¶ï¼Œè¿”å›åˆ—è¡¨ """
    data = []
    with open(file_path, "r", encoding="utf-8") as file:
        for line in file:
            try:
                data.append(json.loads(line.strip()))
            except json.JSONDecodeError:
                print(f"âš ï¸ æ— æ³•è§£æè¡Œï¼š{line.strip()}")
    return data

def calculate_metrics(true_data, pred_data):
    metrics = {
        "accusation": {"TP": 0, "FP": 0, "FN": 0},
        "relevant_articles": {"TP": 0, "FP": 0, "FN": 0}
    }

    skipped = 0  # è·³è¿‡ç©ºé¢„æµ‹æ ·æœ¬è®¡æ•°

    for true_item, pred_item in zip(true_data, pred_data):
        true_meta = true_item.get("meta", {})
        pred_meta = pred_item.get("meta", {})

        true_accusations = set(normalize_accusation(a) for a in true_meta.get("accusation", []))
        true_articles = set(true_meta.get("relevant_articles", []))

        pred_accusations = set(normalize_accusation(a) for a in pred_meta.get("accusation", []))
        pred_articles = set(pred_meta.get("relevant_articles", []))

        # âœ… è·³è¿‡ç©ºé¢„æµ‹æ ·æœ¬ï¼ˆå³ç»“æ„åŒ–å¤±è´¥çš„ï¼‰
        if not pred_accusations and not pred_articles:
            skipped += 1
            continue

        # --- accusation ---
        tp_acc = len(true_accusations & pred_accusations)
        fp_acc = len(pred_accusations - true_accusations)
        fn_acc = len(true_accusations - pred_accusations)

        # --- articles ---
        tp_art = len(true_articles & pred_articles)
        fp_art = len(pred_articles - true_articles)
        fn_art = len(true_articles - pred_articles)

        metrics["accusation"]["TP"] += tp_acc
        metrics["accusation"]["FP"] += fp_acc
        metrics["accusation"]["FN"] += fn_acc

        metrics["relevant_articles"]["TP"] += tp_art
        metrics["relevant_articles"]["FP"] += fp_art
        metrics["relevant_articles"]["FN"] += fn_art

    return metrics, skipped


def compute_precision_recall(tp, fp, fn):
    """ è®¡ç®— Precision å’Œ Recall """
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0
    return precision, recall

def main():
    # åŠ è½½æ•°æ®
    print("ğŸ”„ æ­£åœ¨åŠ è½½æ•°æ®...")
    true_data = load_jsonl(test_path)
    pred_data = load_jsonl(result_path)

    # æ•°æ®é•¿åº¦æ ¡éªŒ
    if len(true_data) != len(pred_data):
        print(f"âš ï¸ æ•°æ®é•¿åº¦ä¸ä¸€è‡´ï¼šæµ‹è¯•é›† {len(true_data)} æ¡ï¼Œç”Ÿæˆç»“æœ {len(pred_data)} æ¡")
        return

    # è®¡ç®—æŒ‡æ ‡
    metrics, skipped = calculate_metrics(true_data, pred_data)

    # è®¡ç®— Precision å’Œ Recall
    acc_tp, acc_fp, acc_fn = metrics["accusation"].values()
    art_tp, art_fp, art_fn = metrics["relevant_articles"].values()

    acc_precision, acc_recall = compute_precision_recall(acc_tp, acc_fp, acc_fn)
    art_precision, art_recall = compute_precision_recall(art_tp, art_fp, art_fn)

    print(f"\nğŸ“Š è¯„ä¼°ç»“æœï¼ˆå·²è·³è¿‡ç©ºé¢„æµ‹æ ·æœ¬ {skipped} æ¡ï¼‰ï¼š")
    print(f"ã€ç½ªå - Precisionã€‘: {acc_precision:.4f}")
    print(f"ã€ç½ªå - Recallã€‘: {acc_recall:.4f}")
    print(f"ã€æ³•æ¡ - Precisionã€‘: {art_precision:.4f}")
    print(f"ã€æ³•æ¡ - Recallã€‘: {art_recall:.4f}")

if __name__ == "__main__":
    main()
